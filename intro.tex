\section*{Introduction}
Data emerging from today's biological experiments are not merely ``big'' but increasingly multimodal and dynamic, as projects quickly move to new technologies and experimental paradigms \cite{howe_big_2008, maze_analytical_2014, editorial_focus_2014, anderson_issues_2007, kandel_neuroscience_2013, gray_scientific_2005}.
In our field of neuroscience, a single experiment may involve several signal acquisition modalities such as imaging, multi-channel electrophysiology, genetic sequencing, optical stimulation, behavioral recordings, and an array of other techniques \cite{reimer_pupil_2014,froudarakis_population_2014}.

Concerted effort must be applied to maintain the integrity and reproducibility of scientific findings by keeping data intelligible and uncorrupted over months and years of experiments.
Data shared between research groups are particularly susceptible to confusion and corruption during data transfers and concurrent access. 
Data integrity must be preserved when it is accessed by multiple computers performing parallel and distributed computations in scenarios such as cluster or cloud computing, even when some jobs are interrupted.

Flexible data access can greatly increase productivity during data analysis to obtain specific cross-sections stored data based on diverse criteria from multiple datasets as in the case of summary statistics across multiple experiments.
When using the file system for organizing data, such analysis may require traversing folders and files, parse their contents, and select and assemble the necessary data for each analysis \cite{anderson_issues_2007}.
Changing experimental configurations require careful adaptations in the structure of associated data repositories and tedious reconfiguration of analysis scripts.

In contrast to file systems, relational databases explicitly maintain data integrity and offer flexible access to cross-sections of the data \cite{codd_relational_1970}. 
A relational database preserves consistency and referential integrity even as multiple users and processes manipulate data concurrently or if a process terminates unexpectedly.
Unlike a file system, a database is not an inert repository designed to simply reproduce data in their original form: instead, it provides a way to access specific and precise cross-sections of the data in order to answer questions unforeseen at the time the data are deposited.
A database system also defines and enforces real-world constraints and relationships between data elements, even as experimental paradigms change over time.
It communicates and enforces these relationships because they are inherent in the structure of the data itself.
This form of self-documentation enables new users to readily understand the architecture of an unfamiliar data set.

Here we describe an open-source framework, DataJoint, to help scientists organize, populate, and query large volumes of data.
In contrast to existing database systems and query languages which are overgrown with extraneous complexity \cite{date_sql_2011,manyam_relax_2012},
DataJoint introduces a minimal set of operators that allow flexible, efficient, and expressive queries to retrieve exactly the data one needs.
Unlike other domain-specific data management tools \cite{manyam_relax_2012, gunay_database_2009, schutter_review_2009, small_database-managed_2009, brown_overview_2010, shi_synapticdb_2011, pittendrigh_neurosys_2003}, DataJoint is general and extensible, as it is not tied to particular file formats, acquisition systems, or data modalities.
At its back end, DataJoint is powered by the flexible and scalable open-source relational database management system MySQL (or its equivalents such as MariaDB).
However, DataJoint users do not need to learn SQL. They can manipulate data transparently through two of the most popular languages for scientific data analysis: Python and MATLAB.
Data can be concurrently accessed and manipulated by multiple users using either language, or distributed across multiple computers for parallel processing.
